# **OS Concurrency Study â€“ Adaptive Task Execution Server**

## ğŸ“Œ Project Overview

This project is an **Operating Systemsâ€“focused concurrency study** that analyzes how different **execution models** and **scheduling policies** behave under diverse workloads.

Instead of treating concurrency as a black box, the project explicitly separates:

* **Scheduling policy** (FIFO vs Priority)
* **Execution mechanism** (threads, processes, async)
* **Workload characteristics** (CPU, IO, memory, mixed, ML)

The goal is to **measure, compare, and explain OS-level behavior** such as waiting time, throughput, CPU utilization, context switching, and fairness.

---

## ğŸ¯ Objectives

* Compare **single-threaded, multi-threaded, multi-process, and async** servers
* Analyze **FIFO vs Priority scheduling** within the server
* Study the **GIL impact** on CPU-bound workloads
* Measure **OS-level metrics** using `psutil`
* Produce **reproducible experiments** with structured results

---

## ğŸ§  Key OS Concepts Covered

* Concurrency vs Parallelism
* Scheduling policies (FIFO, Priority)
* Waiting time, turnaround time, starvation
* Thread vs process overhead
* GIL effects in CPython
* Async IO vs blocking execution
* Context switches and CPU utilization

---

## ğŸ—ï¸ High-Level Architecture

```
Client Request
     â†“
Server (/run endpoint)
     â†“
Scheduler (FIFO / Priority)
     â†“
Dispatcher
     â†“
Executor (Thread / Process / Async)
     â†“
Workload Execution
     â†“
Metrics Collection (psutil)
     â†“
Experiment Logs â†’ Analysis â†’ Report
```

---

## ğŸ“‚ Project Structure (Simplified)

```
src/
â”œâ”€â”€ core/          # Job abstraction
â”œâ”€â”€ scheduler/     # FIFO & Priority scheduling policies
â”œâ”€â”€ dispatch/      # Scheduler â†’ Executor bridge
â”œâ”€â”€ executors/     # Thread, Process, Async execution backends
â”œâ”€â”€ servers/       # Flask (baseline/thread/process), FastAPI (async)
â”œâ”€â”€ workloads/     # CPU, IO, Memory, Mixed, ML workloads
â”œâ”€â”€ utils/         # Metrics, logging, experiment logging

experiments/
â”œâ”€â”€ analysis/      # Summarization & plotting scripts

results/           # Experiment outputs (JSONL, CSV, plots)
docs/              # Architecture, API, experiments, results docs
config/            # Experiment & logging configuration
```

---

## âš™ï¸ Workloads Implemented

* **CPU-bound**: Fibonacci, matrix multiplication
* **IO-bound**: File operations, sleep simulation
* **Memory-bound**: Large array allocation & processing
* **Mixed**: CPU â†’ IO and IO â†’ CPU
* **ML (lightweight)**: Predict-only Linear Regression (model loaded once)

All workloads are **parameterized** to allow controlled scaling.

---

## ğŸ§© Scheduling Policies

* **FIFO**: Fair, simple baseline
* **Priority**: Task-based priority scheduling

  * CPU = High
  * ML = Medium
  * IO = Low

Metrics analyzed:

* Waiting time
* Tail latency (p95/p99)
* Starvation indicators
* Fairness (variation in waiting time)

---

## ğŸ“Š Metrics Collected

Per request:

* Latency (execution time)
* Waiting time (scheduler delay)
* CPU time (user/system)
* Memory usage (RSS delta)
* Context switch deltas

All raw data is stored as **JSONL** for reproducibility.

---

## ğŸ§ª Experiments

* Load testing via **Locust**
* Controlled experiment matrix (users, workload types, scheduler, executor)
* Results summarized into CSV and plotted

See: `docs/experiments.md`

---

## ğŸ–¥ï¸ Platform Notes

* Primary development: **Windows**
* OS-level analysis enhanced via **WSL2 (Ubuntu)**
* `psutil` used for profiling
* `perf` noted as future work due to WSL limitations

---

## ğŸš€ Setup (Quick)

```bash
git clone <repo-url>
cd Process_Task-server
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

Run server:

```bash
python src/servers/flask_app.py
# or
uvicorn src.servers.fastapi_app:app
```

---

## ğŸ“˜ Documentation

* `docs/architecture.md` â€“ system design & flow
* `docs/api.md` â€“ API contract
* `docs/experiments.md` â€“ experiment execution
* `docs/results.md` â€“ interpreting outputs
* `docs/README.md` â€“ documentation index (start here for detailed docs)
---

## ğŸ“Œ Status

**Phase 1: Active**

* Workloads âœ”
* Scheduling âœ”
* Baseline & threaded servers âœ”
* Metrics & logging âœ”

---

## ğŸ‘¨â€ğŸ« Academic Context

This project is designed as an **OS course project**, emphasizing **analysis and reasoning** over raw performance, and is structured to be **viva-defensible**.

---
